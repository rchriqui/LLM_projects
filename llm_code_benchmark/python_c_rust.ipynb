{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a13b971",
      "metadata": {},
      "source": [
        "# Python → C++ via LLMs\n",
        "\n",
        "This notebook uses **OpenRouter** to call multiple LLMs that convert Python code to C++. Each model generates C++ from the same Python snippet; we then **compile and run** each result and **rank models by execution time**, including how much faster the C++ is than the original Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "a582deac",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import subprocess\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "d223d951",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenRouter API Key exists and begins sk-or-\n"
          ]
        }
      ],
      "source": [
        "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
        "if openrouter_api_key:\n",
        "    print(f\"OpenRouter API Key exists and begins {openrouter_api_key[:6]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d03c59b1",
      "metadata": {},
      "source": [
        "Leaderboard coding:\n",
        "\n",
        "- Gemini 3 pro preview\n",
        "- codex 5.2\n",
        "- Claude opus 4.6\n",
        "- Gemini 3 flash\n",
        "- Kimi K2.5\n",
        "- GLM 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "70309330",
      "metadata": {},
      "outputs": [],
      "source": [
        "models = ['google/gemini-3-pro-preview', 'openai/gpt-5.2-codex', 'anthropic/claude-opus-4.6', 'google/gemini-3-flash-preview', 'moonshotai/kimi-k2.5', 'z-ai/glm-5']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c2410ab",
      "metadata": {},
      "source": [
        "## 2. Models & OpenRouter client\n",
        "\n",
        "Models to compare (coding leaderboard). The client talks to OpenRouter’s API so we can call any of these with the same interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "01f14c8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# OpenRouter client (OpenAI-compatible API)\n",
        "openrouter = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=openrouter_api_key,\n",
        ")\n",
        "OPENROUTER_MODEL = models[0]  # e.g. 'google/gemini-3-pro-preview'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e5ab707b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'os': {'system': 'Darwin',\n",
              "  'arch': 'x86_64',\n",
              "  'release': '21.6.0',\n",
              "  'version': 'Darwin Kernel Version 21.6.0: Mon Jun 24 00:56:10 PDT 2024; root:xnu-8020.240.18.709.2~1/RELEASE_X86_64',\n",
              "  'kernel': '21.6.0',\n",
              "  'distro': None,\n",
              "  'wsl': False,\n",
              "  'rosetta2_translated': False,\n",
              "  'target_triple': 'x86_64-apple-darwin21.6.0'},\n",
              " 'package_managers': ['xcode-select (CLT)'],\n",
              " 'cpu': {'brand': 'Intel(R) Core(TM) i5-5350U CPU @ 1.80GHz',\n",
              "  'cores_logical': 4,\n",
              "  'cores_physical': 2,\n",
              "  'simd': ['AVX2', 'FMA']},\n",
              " 'toolchain': {'compilers': {'gcc': 'Apple clang version 14.0.0 (clang-1400.0.29.202)',\n",
              "   'g++': 'Apple clang version 14.0.0 (clang-1400.0.29.202)',\n",
              "   'clang': 'Apple clang version 14.0.0 (clang-1400.0.29.202)',\n",
              "   'msvc_cl': ''},\n",
              "  'build_tools': {'cmake': '', 'ninja': '', 'make': 'GNU Make 3.81'},\n",
              "  'linkers': {'ld_lld': ''}}}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from system_info import retrieve_system_info\n",
        "\n",
        "system_info = retrieve_system_info()\n",
        "system_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "d29d5597",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Commands used to build and run generated C++ (passed to the LLM in the prompt)\n",
        "compile_command = [\"clang++\", \"-std=c++17\", \"-Ofast\", \"-mcpu=native\", \"-flto=thin\", \"-fvisibility=hidden\", \"-DNDEBUG\", \"main.cpp\", \"-o\", \"main\"]\n",
        "run_command = [\"./main\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "b177e24c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiler: Apple clang version 14.0.0 (clang-1400.0.29.202)\n",
            "Target: x86_64-apple-darwin21.6.0\n",
            "Thread model: posix\n",
            "InstalledDir: /Library/Developer/CommandLineTools/usr/bin\n",
            "\n",
            "Run output: C++ is running on this computer.\n",
            "✓ C++ toolchain OK\n"
          ]
        }
      ],
      "source": [
        "# Verify C++ toolchain on this computer\n",
        "_verify_cpp = \"\"\"\n",
        "#include <iostream>\n",
        "int main() {\n",
        "    std::cout << \"C++ is running on this computer.\\\\n\";\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "with open(\"_verify_cpp.cpp\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(_verify_cpp)\n",
        "print(\"Compiler:\", subprocess.run([\"clang++\", \"--version\"], capture_output=True, text=True).stdout.split(\"\\\\n\")[0])\n",
        "result = subprocess.run([\"clang++\", \"-std=c++17\", \"_verify_cpp.cpp\", \"-o\", \"_verify_cpp_exe\"], capture_output=True, text=True, timeout=10)\n",
        "if result.returncode != 0:\n",
        "    print(\"Compile failed:\", result.stderr)\n",
        "else:\n",
        "    run_result = subprocess.run([\"./_verify_cpp_exe\"], capture_output=True, text=True, timeout=5)\n",
        "    print(\"Run output:\", run_result.stdout.strip())\n",
        "    print(\"✓ C++ toolchain OK\" if run_result.returncode == 0 else \"Run failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "45c6c6e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prompt used for Python→C++ conversion (LLM sees this as system message)\n",
        "system_prompt = \"\"\"\n",
        "Your task is to convert Python code into high performance C++ code.\n",
        "Respond only with C++ code. Do not provide any explanation other than occasional comments.\n",
        "The C++ response needs to produce an identical output in the fastest possible time.\n",
        "\"\"\"\n",
        "\n",
        "def user_prompt_for(python):\n",
        "    return f\"\"\"\n",
        "Port this Python code to C++ with the fastest possible implementation that produces identical output in the least time.\n",
        "The system information is:\n",
        "{system_info}\n",
        "Your response will be written to a file called main.cpp and then compiled and executed; the compilation command is:\n",
        "{compile_command}\n",
        "Respond only with C++ code.\n",
        "Python code to port:\n",
        "\n",
        "```python\n",
        "{python}\n",
        "```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fd86e60",
      "metadata": {},
      "source": [
        "### Verify C++ on this computer\n",
        "\n",
        "Quick check that `clang++` is available and can compile/run a small C++ program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "34cfa035",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build chat messages and call API; port() also writes main.cpp and returns the C++ string\n",
        "def messages_for(python):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
        "    ]\n",
        " \n",
        "def write_output(cpp):\n",
        "    with open(\"main.cpp\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(cpp)\n",
        "\n",
        "def port(client, model, python):\n",
        "    reasoning_effort = \"high\" if 'gpt' in model else None\n",
        "    response = client.chat.completions.create(model=model, messages=messages_for(python), reasoning_effort=reasoning_effort)\n",
        "    reply = response.choices[0].message.content\n",
        "    reply = reply.replace('```cpp','').replace('```','')\n",
        "    write_output(reply)\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "e2096326",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample Python: pi via series (long enough to measure run time)\n",
        "pi = \"\"\"\n",
        "import time\n",
        "\n",
        "def calculate(iterations, param1, param2):\n",
        "    result = 1.0\n",
        "    for i in range(1, iterations+1):\n",
        "        j = i * param1 - param2\n",
        "        result -= (1/j)\n",
        "        j = i * param1 + param2\n",
        "        result += (1/j)\n",
        "    return result\n",
        "\n",
        "start_time = time.time()\n",
        "result = calculate(200_000_000, 4, 1) * 4\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Result: {result:.12f}\")\n",
        "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "d231584a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_python(code):\n",
        "    globals = {\"__builtins__\": __builtins__}\n",
        "    exec(code, globals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "e4f83d90",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result: 3.141592656089\n",
            "Execution Time: 79.472572 seconds\n"
          ]
        }
      ],
      "source": [
        "run_python(pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0cb65a5",
      "metadata": {},
      "source": [
        "### Single-model conversion (optional)\n",
        "\n",
        "The snippet we’ll convert: a **π calculation** that runs long enough to measure execution time. The same code is used as the Python baseline and as input for every model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d557664f",
      "metadata": {},
      "outputs": [],
      "source": [
        "port(openrouter, OPENROUTER_MODEL, pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3e27067",
      "metadata": {},
      "source": [
        "## 6. Benchmark: rank models by C++ speed\n",
        "\n",
        "Runs the **Python baseline** once, then for **each model**: generate C++, compile, run, and time. Results are sorted by C++ execution time; we also report **how many times faster** each C++ is than the Python version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "a273de33",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Python → C++ benchmark: which model generates the fastest code? ===\n",
            "\n",
            "Timing Python baseline ... 65.482s\n",
            "\n",
            "[1/6] google/gemini-3-pro-preview ... compile/run failed\n",
            "[2/6] openai/gpt-5.2-codex ... 2.226s  (29.4× faster than Python)\n",
            "[3/6] anthropic/claude-opus-4.6 ... compile/run failed\n",
            "[4/6] google/gemini-3-flash-preview ... 1.371s  (47.8× faster than Python)\n",
            "[5/6] moonshotai/kimi-k2.5 ... compile/run failed\n",
            "[6/6] z-ai/glm-5 ... 1.634s  (40.1× faster than Python)\n",
            "\n",
            "============================================================\n",
            "Python baseline: 65.482s\n",
            "\n",
            "--- Ranking: C++ generated by each model (fastest first) ---\n",
            "  1. google/gemini-3-flash-preview\n",
            "     C++ time: 1.371s  →  47.8× faster than Python\n",
            "  2. z-ai/glm-5\n",
            "     C++ time: 1.634s  →  40.1× faster than Python\n",
            "  3. openai/gpt-5.2-codex\n",
            "     C++ time: 2.226s  →  29.4× faster than Python\n",
            "  4. google/gemini-3-pro-preview: failed\n",
            "  5. anthropic/claude-opus-4.6: failed\n",
            "  6. moonshotai/kimi-k2.5: failed\n",
            "\n",
            "Winner: google/gemini-3-flash-preview — 47.8× faster than Python (65.482s → 1.371s)\n"
          ]
        }
      ],
      "source": [
        "# Time Python once, then each model: generate C++, compile, run, rank by C++ time and speedup vs Python\n",
        "import time as time_module\n",
        "\n",
        "PYTHON_BASELINE_PATH = \"_bench_python.py\"\n",
        "\n",
        "def time_python(python_code):\n",
        "    \"\"\"Run the Python code in a subprocess and return execution time in seconds.\"\"\"\n",
        "    with open(PYTHON_BASELINE_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(python_code)\n",
        "    t0 = time_module.perf_counter()\n",
        "    subprocess.run([sys.executable, PYTHON_BASELINE_PATH], check=True, capture_output=True, timeout=600)\n",
        "    return time_module.perf_counter() - t0\n",
        "\n",
        "def benchmark_models(python_code=pi, models_to_run=None):\n",
        "    \"\"\"\n",
        "    1. Time the original Python code (baseline).\n",
        "    2. Each model in models_to_run (or all models) generates C++; we compile, run, and time each.\n",
        "    3. Rank by C++ execution time and show speedup vs Python.\n",
        "    \"\"\"\n",
        "    if models_to_run is None:\n",
        "        models_to_run = models\n",
        "    print(\"=== Python → C++ benchmark\" + (f\" (retry {len(models_to_run)} models)\" if models_to_run is not models else \"\") + \" ===\\n\")\n",
        "    print(\"Timing Python baseline ...\", end=\" \", flush=True)\n",
        "    python_time = time_python(python_code)\n",
        "    print(f\"{python_time:.3f}s\\n\")\n",
        "\n",
        "    results = []  # (model, cpp_time_seconds, success, error_msg)\n",
        "    base_compile = [\"clang++\", \"-std=c++17\", \"-Ofast\", \"-mcpu=native\", \"-flto=thin\", \"-fvisibility=hidden\", \"-DNDEBUG\"]\n",
        "\n",
        "    for i, model in enumerate(models_to_run):\n",
        "        slug = model.replace(\"/\", \"_\")\n",
        "        cpp_path = f\"generated_{slug}.cpp\"\n",
        "        exe_name = f\"main_{slug}\"\n",
        "        print(f\"[{i+1}/{len(models_to_run)}] {model} ...\", end=\" \", flush=True)\n",
        "        try:\n",
        "            cpp = port(openrouter, model, python_code)\n",
        "            with open(cpp_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(cpp)\n",
        "            compile_cmd = base_compile + [cpp_path, \"-o\", exe_name]\n",
        "            subprocess.run(compile_cmd, check=True, text=True, capture_output=True, timeout=60)\n",
        "            t0 = time_module.perf_counter()\n",
        "            subprocess.run([f\"./{exe_name}\"], check=True, text=True, capture_output=True, timeout=300, cwd=os.getcwd())\n",
        "            elapsed = time_module.perf_counter() - t0\n",
        "            results.append((model, elapsed, True, None))\n",
        "            speedup = python_time / elapsed\n",
        "            print(f\"{elapsed:.3f}s  ({speedup:.1f}× faster than Python)\")\n",
        "        except subprocess.TimeoutExpired:\n",
        "            results.append((model, float(\"inf\"), False, \"timeout\"))\n",
        "            print(\"timeout\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            results.append((model, float(\"inf\"), False, (e.stderr or e.stdout or str(e))[:200]))\n",
        "            print(\"compile/run failed\")\n",
        "        except Exception as e:\n",
        "            results.append((model, float(\"inf\"), False, str(e)[:200]))\n",
        "            print(\"error\")\n",
        "\n",
        "    results.sort(key=lambda x: x[1])\n",
        "    return python_time, results\n",
        "\n",
        "# Run benchmark: Python baseline + each model's C++ → rank by speed\n",
        "python_time, ranking = benchmark_models(pi)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Python baseline:\", f\"{python_time:.3f}s\")\n",
        "print(\"\\n--- Ranking: C++ generated by each model (fastest first) ---\")\n",
        "for rank, (model, cpp_t, ok, err) in enumerate(ranking, 1):\n",
        "    if ok:\n",
        "        speedup = python_time / cpp_t\n",
        "        print(f\"  {rank}. {model}\")\n",
        "        print(f\"     C++ time: {cpp_t:.3f}s  →  {speedup:.1f}× faster than Python\")\n",
        "    else:\n",
        "        print(f\"  {rank}. {model}: failed\")\n",
        "if ranking and ranking[0][1] != float(\"inf\"):\n",
        "    best_model, best_t, _, _ = ranking[0]\n",
        "    print(f\"\\nWinner: {best_model} — {python_time/best_t:.1f}× faster than Python ({python_time:.3f}s → {best_t:.3f}s)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "9d83024d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compile_and_run():\n",
        "    subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
        "    print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
        "    print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
        "    print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6fb2afb8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_python(code):\n",
        "    globals_dict = {\"__builtins__\": __builtins__}\n",
        "\n",
        "    buffer = io.StringIO()\n",
        "    old_stdout = sys.stdout\n",
        "    sys.stdout = buffer\n",
        "\n",
        "    try:\n",
        "        exec(code, globals_dict)\n",
        "        output = buffer.getvalue()\n",
        "    except Exception as e:\n",
        "        output = f\"Error: {e}\"\n",
        "    finally:\n",
        "        sys.stdout = old_stdout\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a8e001ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compile_and_run():\n",
        "    try:\n",
        "        subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
        "        print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
        "        print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
        "        print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"An error occurred:\\n{e.stderr}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c87f5a04",
      "metadata": {},
      "outputs": [],
      "source": [
        "def port(model: str, python_code: str) -> str:\n",
        "    \"\"\"Convert Python code to C++ using the selected OpenRouter model.\"\"\"\n",
        "    if not python_code or not python_code.strip():\n",
        "        return \"\"\n",
        "    client = OpenAI(\n",
        "        base_url=\"https://openrouter.ai/api/v1\",\n",
        "        api_key=openrouter_api_key,\n",
        "    )\n",
        "    import json\n",
        "    sys_str = json.dumps(system_info, indent=2)\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"You are a code conversion expert. Convert the user's Python code to idiomatic C++ that compiles on the target system. Only output the C++ code, no explanation. Target system info:\\n{sys_str}\",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": python_code},\n",
        "        ],\n",
        "    )\n",
        "    return (response.choices[0].message.content or \"\").strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34d072d9",
      "metadata": {},
      "source": [
        "### Retry only failed models\n",
        "\n",
        "Run this cell to re-run **only** the models that failed (compile/run failed). Edit `failed_models` to match the ones you want to retry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "14dfb49f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python baseline: 68.694s\n",
            "\n",
            "[1/3] google/gemini-3-pro-preview ... compile/run failed\n",
            "[2/3] anthropic/claude-opus-4.6 ... compile/run failed\n",
            "[3/3] moonshotai/kimi-k2.5 ... 3.421s  (20.1× faster than Python)\n",
            "\n",
            "--- Retry results (fastest first) ---\n",
            "  1. moonshotai/kimi-k2.5: 3.421s  (20.1× faster than Python)\n",
            "  2. google/gemini-3-pro-preview: failed\n",
            "  3. anthropic/claude-opus-4.6: failed\n"
          ]
        }
      ],
      "source": [
        "# Retry only the models that failed (edit failed_models to match your last run).\n",
        "# Self-contained: does not depend on benchmark_models() signature.\n",
        "import time as _time\n",
        "failed_models = [\n",
        "    \"google/gemini-3-pro-preview\",\n",
        "    \"anthropic/claude-opus-4.6\",\n",
        "    \"moonshotai/kimi-k2.5\",\n",
        "]\n",
        "base_compile = [\"clang++\", \"-std=c++17\", \"-Ofast\", \"-mcpu=native\", \"-flto=thin\", \"-fvisibility=hidden\", \"-DNDEBUG\"]\n",
        "\n",
        "with open(\"_bench_python.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(pi)\n",
        "_t0 = _time.perf_counter()\n",
        "subprocess.run([sys.executable, \"_bench_python.py\"], check=True, capture_output=True, timeout=600)\n",
        "python_time_retry = _time.perf_counter() - _t0\n",
        "print(f\"Python baseline: {python_time_retry:.3f}s\\n\")\n",
        "\n",
        "results_retry = []\n",
        "for i, model in enumerate(failed_models):\n",
        "    slug = model.replace(\"/\", \"_\")\n",
        "    cpp_path = f\"generated_{slug}.cpp\"\n",
        "    exe_name = f\"main_{slug}\"\n",
        "    print(f\"[{i+1}/{len(failed_models)}] {model} ...\", end=\" \", flush=True)\n",
        "    try:\n",
        "        cpp = port(openrouter, model, pi)\n",
        "        with open(cpp_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(cpp)\n",
        "        subprocess.run(base_compile + [cpp_path, \"-o\", exe_name], check=True, text=True, capture_output=True, timeout=60)\n",
        "        _t0 = _time.perf_counter()\n",
        "        subprocess.run([f\"./{exe_name}\"], check=True, text=True, capture_output=True, timeout=300, cwd=os.getcwd())\n",
        "        elapsed = _time.perf_counter() - _t0\n",
        "        results_retry.append((model, elapsed, True, None))\n",
        "        print(f\"{elapsed:.3f}s  ({python_time_retry/elapsed:.1f}× faster than Python)\")\n",
        "    except subprocess.TimeoutExpired:\n",
        "        results_retry.append((model, float(\"inf\"), False, \"timeout\"))\n",
        "        print(\"timeout\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        results_retry.append((model, float(\"inf\"), False, None))\n",
        "        print(\"compile/run failed\")\n",
        "    except Exception as e:\n",
        "        results_retry.append((model, float(\"inf\"), False, None))\n",
        "        print(\"error\")\n",
        "\n",
        "results_retry.sort(key=lambda x: x[1])\n",
        "print(\"\\n--- Retry results (fastest first) ---\")\n",
        "for rank, (model, cpp_t, ok, _) in enumerate(results_retry, 1):\n",
        "    if ok:\n",
        "        print(f\"  {rank}. {model}: {cpp_t:.3f}s  ({python_time_retry/cpp_t:.1f}× faster than Python)\")\n",
        "    else:\n",
        "        print(f\"  {rank}. {model}: failed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed0b178",
      "metadata": {},
      "source": [
        "## 7. Gradio UI (optional)\n",
        "\n",
        "Web interface: pick a model, paste Python code, click **Convert code** to get C++ in the other box."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "0ab447c7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7861\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with gr.Blocks() as ui:\n",
        "    with gr.Row():\n",
        "        python = gr.Textbox(label=\"Python code:\", lines=28, value=pi)\n",
        "        cpp = gr.Textbox(label=\"C++ code:\", lines=28)\n",
        "    with gr.Row():\n",
        "        model = gr.Dropdown(models, label=\"Select model\", value=models[0])\n",
        "        convert = gr.Button(\"Convert code\")\n",
        "\n",
        "    convert.click(port, inputs=[model, python], outputs=[cpp])\n",
        "\n",
        "ui.launch(inbrowser=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
